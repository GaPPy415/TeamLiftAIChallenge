{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:13:22.224763Z",
     "start_time": "2025-02-13T15:13:19.079870Z"
    }
   },
   "cell_type": "code",
   "source": "from transformers import pipeline",
   "id": "b2ac9c14d4833ed0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:13:34.617124Z",
     "start_time": "2025-02-13T15:13:34.613120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Handler:\n",
    "    def __init__(self):\n",
    "        self.classifier = pipeline('zero-shot-classification')\n",
    "        self.skills = ['Python', 'relational database', 'Software engineering', 'data science', 'NLP', 'natural language processing', 'database engineer',\n",
    "          'data engineer', 'data analyst', 'data visualization', 'data analytics', 'data mining', 'data warehousing', 'data modeling', 'data management',\n",
    "          'data cleaning', 'data wrangling', 'data preprocessing', 'data transformation', 'data manipulation', 'data extraction', 'data integration',\n",
    "          'data loading', 'data migration', 'data governance', 'data quality', 'data quality control', 'data quality assurance', 'data quality management',\n",
    "          'data quality monitoring', 'data quality assessment', 'data quality improvement', 'data quality enhancement', 'data quality evaluation',\n",
    "          'data quality validation', 'data quality verification', 'data quality reporting', 'data quality analysis', 'data quality measurement']\n",
    "        # Additional skills generated by GitHub Copilot for testing\n",
    "\n",
    "    def search(self, search_query):\n",
    "        return self.classifier(search_query, candidate_labels=self.skills)"
   ],
   "id": "8fc70c0986b4ddb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:13:43.938502Z",
     "start_time": "2025-02-13T15:13:39.741104Z"
    }
   },
   "cell_type": "code",
   "source": "handler = Handler()",
   "id": "445dcb970e32c173",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to FacebookAI/roberta-large-mnli and revision 2a8f12d (https://huggingface.co/FacebookAI/roberta-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\David\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\David\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:36:15.893730Z",
     "start_time": "2025-02-13T15:36:15.890724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_result(result):\n",
    "    for x in result['labels']:\n",
    "        score = result['scores'][result['labels'].index(x)]\n",
    "        print(x, score)"
   ],
   "id": "d9d3ec2fca74ec95",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:40:08.470294Z",
     "start_time": "2025-02-13T15:39:42.272972Z"
    }
   },
   "cell_type": "code",
   "source": "results = [handler.search('databases'), handler.search('machine learning'), handler.search('data science')]",
   "id": "ce09aa8dae509175",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:41:23.155399Z",
     "start_time": "2025-02-13T15:41:23.151398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Databases:')\n",
    "print_result(results[0])\n",
    "print('\\nMachine Learning:')\n",
    "print_result(results[1])\n",
    "print('\\nData Science:')\n",
    "print_result(results[2])"
   ],
   "id": "c1fb5207a21a5da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Databases:\n",
      "data loading 0.10770062357187271\n",
      "data management 0.0744643434882164\n",
      "data science 0.06298145651817322\n",
      "data integration 0.0530095100402832\n",
      "data extraction 0.050035636872053146\n",
      "data preprocessing 0.0482349619269371\n",
      "data wrangling 0.04711293429136276\n",
      "data warehousing 0.04661580175161362\n",
      "data quality 0.036934684962034225\n",
      "data manipulation 0.035948872566223145\n",
      "data modeling 0.0357280857861042\n",
      "data analytics 0.035195861011743546\n",
      "data mining 0.027660222724080086\n",
      "data quality analysis 0.022892814129590988\n",
      "data transformation 0.022533321753144264\n",
      "data quality validation 0.02024589665234089\n",
      "data migration 0.01986468769609928\n",
      "data quality reporting 0.01840132474899292\n",
      "data quality verification 0.016988974064588547\n",
      "data quality enhancement 0.016718318685889244\n",
      "data quality measurement 0.01654435507953167\n",
      "data quality management 0.01507300790399313\n",
      "data visualization 0.015036460943520069\n",
      "data governance 0.014626934193074703\n",
      "data quality assessment 0.014047937467694283\n",
      "relational database 0.012919316999614239\n",
      "data quality evaluation 0.012907148338854313\n",
      "data quality monitoring 0.012892000377178192\n",
      "data quality improvement 0.010928268544375896\n",
      "NLP 0.008917093276977539\n",
      "data analyst 0.008588002994656563\n",
      "Software engineering 0.008210578002035618\n",
      "data engineer 0.008180600591003895\n",
      "Python 0.008044153451919556\n",
      "data quality assurance 0.0076100085861980915\n",
      "data quality control 0.007551487069576979\n",
      "database engineer 0.007055954542011023\n",
      "natural language processing 0.007034166716039181\n",
      "data cleaning 0.004564203321933746\n",
      "\n",
      "Machine Learning:\n",
      "data science 0.176325261592865\n",
      "data transformation 0.05494436249136925\n",
      "data analytics 0.05449286103248596\n",
      "data quality enhancement 0.0479506216943264\n",
      "data modeling 0.04445898160338402\n",
      "data integration 0.0441870279610157\n",
      "data quality improvement 0.044110339134931564\n",
      "data wrangling 0.03875952586531639\n",
      "data management 0.037145111709833145\n",
      "data mining 0.027287185192108154\n",
      "data quality validation 0.024553047493100166\n",
      "data migration 0.023980818688869476\n",
      "data quality analysis 0.02380864880979061\n",
      "data manipulation 0.023710649460554123\n",
      "data quality 0.023457247763872147\n",
      "NLP 0.02239120565354824\n",
      "data extraction 0.02169676125049591\n",
      "data preprocessing 0.020237373188138008\n",
      "data governance 0.019730310887098312\n",
      "data loading 0.018692979589104652\n",
      "data engineer 0.017046455293893814\n",
      "data quality management 0.015455530025064945\n",
      "data quality evaluation 0.015096115879714489\n",
      "data quality assessment 0.013642829842865467\n",
      "data quality measurement 0.013033600524067879\n",
      "data quality verification 0.012851192615926266\n",
      "data visualization 0.012131369672715664\n",
      "data quality assurance 0.011431282386183739\n",
      "data analyst 0.011338571086525917\n",
      "Software engineering 0.010519443079829216\n",
      "Python 0.010122532024979591\n",
      "data quality reporting 0.009951912797987461\n",
      "data quality monitoring 0.009597156196832657\n",
      "data quality control 0.009547022171318531\n",
      "relational database 0.00936928577721119\n",
      "data cleaning 0.008455866016447544\n",
      "database engineer 0.007494567893445492\n",
      "data warehousing 0.005976843647658825\n",
      "natural language processing 0.0050180889666080475\n",
      "\n",
      "Data Science:\n",
      "data science 0.2549007534980774\n",
      "data quality analysis 0.07143285870552063\n",
      "data quality validation 0.059469252824783325\n",
      "data quality measurement 0.04433388635516167\n",
      "data quality verification 0.04055027663707733\n",
      "data quality enhancement 0.03921830654144287\n",
      "data analytics 0.03739064931869507\n",
      "data quality evaluation 0.036425307393074036\n",
      "data quality assessment 0.03531189262866974\n",
      "data quality 0.029986444860696793\n",
      "data quality improvement 0.029138166457414627\n",
      "data extraction 0.027388228103518486\n",
      "data quality monitoring 0.027002476155757904\n",
      "data wrangling 0.018879393115639687\n",
      "data modeling 0.01638122648000717\n",
      "data loading 0.015960097312927246\n",
      "data integration 0.015856387093663216\n",
      "data analyst 0.015476640313863754\n",
      "data management 0.015451891347765923\n",
      "data quality reporting 0.01528285350650549\n",
      "data mining 0.01446359883993864\n",
      "data quality management 0.014127758331596851\n",
      "data preprocessing 0.01367545872926712\n",
      "data transformation 0.012955172918736935\n",
      "database engineer 0.01172863319516182\n",
      "data quality assurance 0.009408045560121536\n",
      "data quality control 0.008512373082339764\n",
      "relational database 0.008046368137001991\n",
      "data migration 0.007737143896520138\n",
      "data engineer 0.0075692986138165\n",
      "data visualization 0.007134255953133106\n",
      "data manipulation 0.006675079930573702\n",
      "NLP 0.006356776691973209\n",
      "Python 0.004998009651899338\n",
      "data cleaning 0.0049646045081317425\n",
      "data governance 0.0048627592623233795\n",
      "Software engineering 0.004154794383794069\n",
      "natural language processing 0.003568201558664441\n",
      "data warehousing 0.003224619198590517\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "26073054f8e86787"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
